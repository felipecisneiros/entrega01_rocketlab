# Databricks notebook source
# MAGIC %md
# MAGIC # <center>Rocket Lab Dados - 2025.2</center>
# MAGIC # <center> Introdu√ß√£o √† Pyspark</center>
# MAGIC ___
# MAGIC Todo o conte√∫do que voc√™ ter√° acesso ao longo desse per√≠odo √© confidencial, n√£o sendo poss√≠vel compartilhar ou comercializar os links ou os materiais recebidos que sejam de propriedade do Programa Rocket Lab da V(dev)
# MAGIC
# MAGIC Dessa forma, ao participar do curso voc√™ est√° aceitando os termos de confidencialidade e n√£o-comercializa√ß√£o dos conte√∫dos que ser√£o recebidos.
# MAGIC ___
# MAGIC
# MAGIC # <center> Objetivos de aprendizado </center>
# MAGIC - Familiarizar-se com as funcionalidades b√°sicas do PySpark
# MAGIC - Ser capaz de carregar dados em um DataFrame
# MAGIC - Ser capaz de realizar manipula√ß√µes b√°sicas de dados
# MAGIC ___
# MAGIC

# COMMAND ----------

# MAGIC %md
# MAGIC ### 1. Juntando DataFrames
# MAGIC
# MAGIC √â muito comum ter a necessidade de juntar *DataFrames* diferentes. Se voc√™ j√° utilizou SQL ou qualquer outro banco de dados relacional, deve conhecer isso como *join*. O Pandas tamb√©m tem a mesma fun√ß√£o utilizando o m√©todo *.merge()*. Antes do exemplo, vamos aprender/relembrar os tipos de *joins* mais comuns:<br>
# MAGIC ![Joining Methods](https://i.imgur.com/HaSBT91.jpg) <br>
# MAGIC Agora, vamos carregar um DataFrame mais simples para testar os tipos de *merge*.

# COMMAND ----------

# MAGIC %md
# MAGIC Para os exemplos abaixo iremos utilizar o Datafram: **metal_bands**, contendo as informa√ß√µes sobre bandas de metal do mundo todo, suas origens e estilos musicais.
# MAGIC
# MAGIC Principais colunas:
# MAGIC - Band ‚Äî nome da banda
# MAGIC - Origin ‚Äî pa√≠s de origem
# MAGIC - Fans ‚Äî n√∫mero aproximado de f√£s
# MAGIC - Formed ‚Äî ano de forma√ß√£o
# MAGIC - Split ‚Äî ano de separa√ß√£o ('-', se ainda ativa)
# MAGIC - Style ‚Äî subg√™nero do metal (ex: Heavy Metal, Black Metal, Thrash Metal)

# COMMAND ----------

from pyspark.sql import SparkSession
from pyspark.sql import functions as F
from pyspark.sql.window import Window

#Criar sess√£o spark
spark = SparkSession.builder.appName("AtividadePraticaSpark").getOrCreate()

# Execute esta c√©lula para carregar o dataframe metal_bands com dados de bandas de metal
metal_bands = spark.table("workspace.default.metal_bands")

metal_bands.printSchema()
display(metal_bands.limit(5))

# COMMAND ----------

# MAGIC %md
# MAGIC Vamos separar alguns dataframes a partir de *metal_bands* para testar os merges. Observe a c√©lula abaixo.

# COMMAND ----------

# ano de forma√ß√£o e pa√≠s das bandas
bands_origin = metal_bands.select('id','band_name','formed','origin')

# estilo das bandas
bands_style = metal_bands.select('id','band_name','style') # estilo das bandas

# bandas que se separaram
bands_split = (metal_bands
               .select('id','band_name','split')
               .where(F.column('split') != "-")
               )

# bandas com mais de 4000 fans
bands_4000_fans = (metal_bands
                   .select('id','band_name','fans')
                   .where(F.column('fans') > 4000)
                   )

# bandas formadas nos EUA
bands_USA = (metal_bands
             .select('id','band_name','formed','origin')
             .where(F.column('origin') == "USA")
             )

# bandas formadas na Su√©cia
bands_Sweden = (metal_bands
                .select('id','band_name','formed','origin')
                .where(F.column('origin') == 'Sweden')
                )

# COMMAND ----------

# MAGIC %md
# MAGIC Vamos criar um DataFrame a partir de ```bands_origin``` e ```bands_split```, utilizando *merge*.

# COMMAND ----------

origin_split = (bands_origin # o DataFrame da esquerda
                .join(bands_split, # o DataFrame da direita
                      on=['id', 'band_name'], # baseado em quais valores em comum (chave)
                      how='inner' # o tipo de join que queremos fazer
                      )
                )
display(origin_split.limit(5))

# COMMAND ----------

# MAGIC %md
# MAGIC √ìtimo! Conseguimos fazer o *Join* de dois *DataFrames*. Observe que utilizamos o argumento ```how='inner'```. Lembre-se que *inner*, *left*, *right* e *outer* ter√£o resultados diferentes, observe os merges abaixo e a explica√ß√£o ao final.

# COMMAND ----------

left_origin_split = (bands_origin
                     .join(bands_split,
                           on= ['id', 'band_name'],
                           how="left"
                           )
                     )
display(left_origin_split.limit(5))

# COMMAND ----------

right_origin_split = (bands_origin
                     .join(bands_split,
                           on= ['id', 'band_name'],
                           how="right"
                           )
                     )
display(right_origin_split.limit(5))

# COMMAND ----------

print('Numero de linhas do DataFrame bands_4000_fans:', bands_4000_fans.count())
print('Numero de linhas do DataFrame bands_USA:', bands_USA.count())
print('----------------------------------------------')

outer_origin_split = (bands_4000_fans
                     .join(bands_USA,
                           on= ['id', 'band_name'],
                           how="outer"
                           )
                     )

print('Numero de linhas do DataFrame ap√≥s Outer entre bands_4000_fans & bands_USA:', outer_origin_split.count())
display(outer_origin_split.limit(5))

# COMMAND ----------

# MAGIC %md
# MAGIC Como podemos ver, os resultados s√£o de fato bem diferentes.
# MAGIC
# MAGIC O *inner* mant√©m apenas os dados das bandas encontradas nos dois dataframes (onde h√° correspond√™ncia de *id*), dessa forma, a posi√ß√£o do dataframe n√£o faz diferen√ßa.
# MAGIC
# MAGIC No *left*, mantemos os dados do dataframe √† esquerda, e trazemos os dados do dataframe √† direita no qual encontrou-se a chave (neste exemplo, o *id* da banda).
# MAGIC
# MAGIC Por outro lado, no *right* ocorre o contr√°rio, mantemos os dados do dataframe √† direita e, quando h√° correspond√™ncia da chave, trazemos os dados do dataframe √† esquerda. Note que o n√∫mero de entradas (*entries*) √© diferente do caso com o *left*. Isso ocorre porque no *left* mantemos os dados de forma√ß√£o das bandas (ou seja, o dataframe cont√©m todas as bandas do .csv), enquanto no *right*, mantemos apenas os dados de bandas que se separaram (e existem muitas bandas que ainda continuam juntas).
# MAGIC
# MAGIC Por fim, no *outer* utilizamos dois dataframes diferentes dos anteriores para facilitar o entendimento. Observe pelos prints que existem apenas 4 bandas com mais de 4000 fans e 1139 bandas formadas nos EUA. Quando fazemos o *join* com *outer*, observe que o total de linhas passa a ser 1143. O que acontece √© que esse tipo de join mant√©m os dados de ambos os dataframes, independente se houve correspond√™ncia de chave ou n√£o.
# MAGIC
# MAGIC Podemos tamb√©m querer apenas concatenar dois *DataDrames*, isto √©, junt√°-los colocando um abaixo do outro. Para isso, utilizamos o m√©todo *.union()*:

# COMMAND ----------

# concatenando bandas formadas nos EUA e bandas formadas na Su√©cia
USA_Sweden = bands_USA.union(bands_Sweden)

print('Numero de linhas do DataFrame bands_USA:', bands_USA.count())
print('Numero de linhas do DataFrame bands_Sweden:', bands_Sweden.count())
print('Numero de linhas do DataFrame ap√≥s union entre bands_USA & bands_Sweden:', USA_Sweden.count())
display(USA_Sweden.limit(5))

# COMMAND ----------

# MAGIC %md
# MAGIC ## Exerc√≠cio 1
# MAGIC O Ultimate Team (FUT) √© um modo do jogo FIFA no qual o jogador monta seu pr√≥prio time adquirindo atletas virtuais.
# MAGIC Cada atleta possui atributos que influenciam seu desempenho em campo ‚Äî como drible, chute, passe, defesa, velocidade e f√≠sico.
# MAGIC
# MAGIC Principais colunas:
# MAGIC - `player_id` ‚Äî identificador √∫nico do jogador
# MAGIC - `player_name` ‚Äî nome do atleta
# MAGIC - `nationality` ‚Äî pa√≠s de origem
# MAGIC - `club` ‚Äî clube atual
# MAGIC - `overall` ‚Äî nota geral do jogador
# MAGIC - `potential` ‚Äî potencial m√°ximo de evolu√ß√£o
# MAGIC - `value_eur, wage_eur` ‚Äî valor de mercado e sal√°rio
# MAGIC - `age, height_cm, weight_kg` ‚Äî caracter√≠sticas f√≠sicas
# MAGIC - `pace, shooting, passing, dribbling, defending, physic` ‚Äî atributos t√©cnicos
# MAGIC
# MAGIC _**Preencha os espacos ____ para carregar os dados e realizar as consultas propostas.**_

# COMMAND ----------

# MAGIC %md
# MAGIC ### Exerc√≠cio 1.1 Fa√ßa a leitura do arquivo fut_players (fut_player_data.csv) e retorne as 5 primeiras linhas

# COMMAND ----------

fut_players = spark.read.table("fut_players_data")

display(fut_players.limit(5))


# COMMAND ----------

# MAGIC %md
# MAGIC ### Exerc√≠cio 1.2 - Retorna a nacionalidade dos jogadores "The Bests"
# MAGIC
# MAGIC S√£o considerados jogadores The Bests os que possuem os atributos de drible (_dribbling_) e chute (_shooting_) superior a 90. 
# MAGIC Ap√≥s a gera√ß√£o do DF _The_Best_ realize o join com o df _nationalities_ para obter a nacionalidade dos jogadores.
# MAGIC
# MAGIC A sua tabela final deve conter as seguintes informa√ß√µes:
# MAGIC - `player_id`
# MAGIC - `player_name`
# MAGIC - `nationality`
# MAGIC - `position`
# MAGIC - `dribbling`
# MAGIC - `shooting`
# MAGIC - `overall`

# COMMAND ----------

the_best = fut_players.filter((fut_players.dribbling > 90) & (fut_players.shooting > 90))

nationalities = (fut_players.select('player_id', 'player_name', 'nationality'))

the_best_nationality = the_best.join(nationalities, "player_id", "left") \
    .select(
        the_best['player_id'],
        the_best['player_name'], 
        nationalities['nationality'],
        the_best['position'],
        the_best['dribbling'],
        the_best['shooting'],
        the_best['overall']
    )

the_best_nationality.display()

# COMMAND ----------

# MAGIC %md
# MAGIC ## 2. Alterando o dataframe
# MAGIC

# COMMAND ----------

# MAGIC %md
# MAGIC Agora iremos utilizar o DataFrame _**pokemon_data**_. Essa base re√∫ne informa√ß√µes sobre os Pok√©mons das diversas gera√ß√µes da franquia, contendo atributos, classifica√ß√µes e estat√≠sticas de batalha.
# MAGIC
# MAGIC Principais Colunas:
# MAGIC - Name ‚Äî nome do Pok√©mon 
# MAGIC - Type 1, Type 2 ‚Äî tipos prim√°rio e secund√°rio (ex: Fire, Water, Grass) 
# MAGIC - HP, Attack, Defense, Sp. Atk, Sp. Def, Speed ‚Äî atributos de combate 
# MAGIC - Generation ‚Äî gera√ß√£o √† qual pertence
# MAGIC - Legendary - Se e ou n√£o um Pok√©mon lend√°rio

# COMMAND ----------

pkmn = spark.table("workspace.default.pokemon_data")

display(pkmn.limit(5))

# COMMAND ----------

# MAGIC %md
# MAGIC At√© o momento apenas utilizamos os dados da forma que nos foram fornecidos, mas e se precis√°ssemos criar alguma coluna que fosse a combina√ß√£o das demais? Por exemplo, caso eu deseje criar uma coluna que corresponde √† soma do ataque e velocidade dos Pok√©mons? Observe abaixo:

# COMMAND ----------

# Criando a coluna desejada
pkmn = pkmn.withColumn("Sum_Attack_Speed", F.col("Attack") + F.col("Speed"))
display(pkmn.limit(5))

# COMMAND ----------

# MAGIC %md
# MAGIC Observe como foi f√°cil! Apenas utilizamos o operador de soma com as duas colunas necess√°rias. Voc√™ pode fazer isso com outras opera√ß√µes tamb√©m, basta utilizar ```-```, ```/``` ou ```*```. Al√©m disso, voc√™ pode combinar quantas colunas quiser!
# MAGIC
# MAGIC Mas e se precisarmos alterar apenas algumas linhas do nosso DataFrame?
# MAGIC
# MAGIC Por exemplo, suponha que voc√™ percebeu que seus dados est√£o errados, e todos os Pok√©mons com velocidade acima de 100 deveriam estar marcados como Type_1 = 'Fire', podemos seguir o procedimento abaixo:

# COMMAND ----------

# Observe os valores unicos da coluna Type_1 para os Pok√©mons com mais de 100 de velocidade
pkmn.filter(pkmn["Speed"] > 100).select("Type_1").distinct().display()

# COMMAND ----------

# Vamos alterar os casos onde Speed √© superior a 100 para Fire
pkmn = pkmn.withColumn(
    "Type_1",
    F.when(pkmn["Speed"] > 100, "Fire").otherwise(pkmn["Type_1"])
)

# COMMAND ----------

# Observe como os valores mudaram
pkmn.filter(pkmn["Speed"] > 100).select("Type_1").distinct().display()

# COMMAND ----------

# MAGIC %md
# MAGIC Relendo o arquivo para desconsiderar os tratamentos de exemplos que fizemos acima

# COMMAND ----------


pkmn = spark.table("workspace.default.pokemon_data")

# Renomeando as colunas
pkmn = (
    pkmn
    .withColumnRenamed("Type 1", "Type_1")
    .withColumnRenamed("Type 2", "Type_2")
    .withColumnRenamed("Sp. Atk", "Sp_Atk")
    .withColumnRenamed("Sp. Def", "Sp_Def")
)



# COMMAND ----------

# MAGIC %md
# MAGIC ## 3. Opera√ß√µes em grupo
# MAGIC
# MAGIC Com PySpark n√≥s podemos aplicar opera√ß√µes em grupos usando o m√©todo *.groupby()*. Ele √© muito √∫til por ser uma forma bem simples de extrair informa√ß√£o de dados agregados. Para utiliz√°-lo, passamos as colunas nas quais queremos agrupar os dados e a opera√ß√£o que queremos fazer. Para exemplificar, vamos ver quantos Pok√©mons lend√°rios cada gera√ß√£o tem:

# COMMAND ----------

pkmn_soma = (pkmn
            .groupBy("Generation") # Campo que sera agrupado
            .agg(
                F.sum(F.col("Legendary").cast("int")) # Converte a coluna "Legendary" em inteiro e faz a soma
                .alias("Qtd_Legendary") # Nomeando a coluna que receber√° o resultado da soma
                )
            )
pkmn_soma.display()

# COMMAND ----------

# MAGIC %md
# MAGIC Podemos obter um relat√≥rio da m√©dia de diversas colunas para cada tipo de Pok√©mon:

# COMMAND ----------

pkmn_media = (pkmn
                .groupBy("Type_1")
                .agg(
                    F.mean("HP").alias("HP_medio"),
                    F.mean("Attack").alias("Attack_medio"),
                    F.mean("Defense").alias("Defense_medio")
                    )
                )
pkmn_media.display()

# COMMAND ----------

# MAGIC %md
# MAGIC
# MAGIC
# MAGIC ###  Exerc√≠cio 2
# MAGIC Use o m√©todo *.groupby()* para descobrir qual pa√≠s tem o melhor *overall* m√©dio. Crie a coluna 'avg_overall'
# MAGIC
# MAGIC Seu df country_avg_overall deve conter as seguintes colunas:
# MAGIC - `nationality`
# MAGIC - `overall`
# MAGIC - `avg_overall`

# COMMAND ----------

from pyspark.sql import functions as F

country_avg_overall = (
    fut_players
    .groupBy("nationality")
    .agg(
        F.avg("overall").alias("avg_overall")
    )
    .select(
        "nationality",
        F.lit("overall").alias("overall"),  
        "avg_overall"
    )
)

melhor = (
    country_avg_overall
    .orderBy(F.col("avg_overall").desc())
    .limit(1)
    .collect()[0]
)

brasil = (
    country_avg_overall
    .filter(F.col("nationality") == "Brazil")
    .collect()[0]
)

display({
    "Melhor overall m√©dio": f"{melhor['nationality']}: {melhor['avg_overall']:.2f}",
    "Overall m√©dio do Brasil": round(brasil['avg_overall'], 2)
})

# COMMAND ----------

# MAGIC %md
# MAGIC Agora n√≥s j√° cobrimos toda a parte b√°sica do Spark! Vamos praticar essa √∫ltima parte!
# MAGIC
# MAGIC ### Exerc√≠cio 2.1
# MAGIC Crie um racional que retorne a classifica√ß√£o para o jogador de acordo com as instru√ß√µes abaixo, ent√£o aplique isso para o dataframe fut_players.
# MAGIC
# MAGIC *Observa√ß√£o:* considere os limites dentro do intervalo de classifica√ß√£o.
# MAGIC exemplo
# MAGIC
# MAGIC -50 cont√©m todos os valores menores que 50 e o valor 50 incluso;
# MAGIC
# MAGIC
# MAGIC 51-60 cont√©m todos os valores entre 51 e 60 com os limites [51,60] inclusos no grupo;
# MAGIC
# MAGIC
# MAGIC e assim por diante ...

# COMMAND ----------

from pyspark.sql import functions as F

fut_players = fut_players.withColumn(
    'classification',
    F.when(F.col('overall') <= 50, "Amador")
     .when(F.col('overall') <= 60, "Ruim")    
     .when(F.col('overall') <= 70, "Ok")       
     .when(F.col('overall') <= 80, "Bom")      
     .when(F.col('overall') <= 90, "√ìtimo")    
     .otherwise("Lenda")                      
)

fut_players.groupBy("classification").count().orderBy("count", ascending=False).display()

# COMMAND ----------

# MAGIC %md
# MAGIC ## Desafio ‚Äî Montando o Time dos Sonhos do üáßüá∑
# MAGIC
# MAGIC Ainda utilizando a base **`fut_players_data`**, imagine que voc√™ √© um grande f√£ do jogo *FIFA*, e deseja montar o **Time dos Sonhos (Dream Team)** do **Brasil**, selecionando os **melhores jogadores por posi√ß√£o**, ou seja, aqueles com o **maior overall** dentro de cada grupo de posi√ß√£o.
# MAGIC
# MAGIC Para isso, adote a **forma√ß√£o t√°tica 4-4-2**, composta por:
# MAGIC
# MAGIC - **1 Goleiro (GK)**  
# MAGIC - **4 Defensores (Defesa)**  
# MAGIC - **4 Meio-campistas (Meio)**  
# MAGIC - **2 Atacantes (Ataque)**  
# MAGIC
# MAGIC ### Objetivo
# MAGIC Criar um *DataFrame* com **11 linhas**, representando o **melhor jogador de cada posi√ß√£o dentro da forma√ß√£o 4-4-2**, com as seguintes colunas:
# MAGIC
# MAGIC - `nationality` ‚Äî nacionalidade do jogador  
# MAGIC - `position_group` ‚Äî posi√ß√£o agrupada (Goleiro, Defesa, Meio, Ataque)  
# MAGIC - `player_name` ‚Äî nome do jogador  
# MAGIC - `overall` ‚Äî nota geral (overall)
# MAGIC
# MAGIC ---
# MAGIC
# MAGIC ### Agrupamento de posi√ß√µes
# MAGIC Para facilitar a an√°lise, agrupe as posi√ß√µes originais da base conforme a tabela abaixo:
# MAGIC
# MAGIC | **position_group** | **Posi√ß√µes inclu√≠das (`position`)** | **Descri√ß√£o** |
# MAGIC |:--------------------|:------------------------------------|:---------------|
# MAGIC | **Goleiro** | `GK` | Jogadores que atuam exclusivamente no gol. |
# MAGIC | **Defesa** | `CB`, `LB`, `RB`, `LWB`, `RWB` | Zagueiros e laterais (defensores). |
# MAGIC | **Meio** | `CM`, `CDM`, `CAM`, `LM`, `RM` | Meio-campistas centrais, volantes e meias ofensivos/laterais. |
# MAGIC | **Ataque** | `ST`, `CF`, `LW`, `RW`, `LF`, `RF` | Atacantes e pontas. |
# MAGIC | **Outros** | *(demais posi√ß√µes n√£o classificadas)* | Jogadores fora do esquema t√°tico principal (ex: cartas especiais). |
# MAGIC
# MAGIC ---
# MAGIC
# MAGIC ### üèÅ Entrega esperada
# MAGIC Seu *DataFrame final* deve retornar **11 jogadores**, representando o **Time dos Sonhos do Brasil (forma√ß√£o 4-4-2)**, conforme os crit√©rios acima.

# COMMAND ----------

from pyspark.sql import functions as F
from pyspark.sql.window import Window

posicao_goleiro = ["GK"]
posicoes_defesa = ["CB", "RB", "LB", "LWB", "RWB"]  
posicoes_meio = ["CM", "CDM", "CAM", "LM", "RM"]  
posicoes_ataque = ["ST", "CF", "LW", "RW", "LF", "RF"] 

jogadores_brasileiros = fut_players.filter(F.col("nationality") == "Brazil")

jogadores_classificados = jogadores_brasileiros.withColumn(
    "position_group",
    F.when(F.col("position").isin(posicao_goleiro), "Goleiro")
     .when(F.col("position").isin(posicoes_defesa), "Defesa")
     .when(F.col("position").isin(posicoes_meio), "Meio")
     .when(F.col("position").isin(posicoes_ataque), "Ataque")
     .otherwise("Outros")
)

window_spec = Window.partitionBy("position_group").orderBy(F.desc("overall"))

dream_team = (
    jogadores_classificados
    .filter(F.col("position_group") != "Outros")
    .withColumn("rank", F.row_number().over(window_spec))
    .filter(
        ((F.col("position_group") == "Goleiro") & (F.col("rank") <= 1)) |
        ((F.col("position_group") == "Defesa") & (F.col("rank") <= 4)) |
        ((F.col("position_group") == "Meio") & (F.col("rank") <= 4)) | 
        ((F.col("position_group") == "Ataque") & (F.col("rank") <= 2))
    )
    .select(
        "nationality",
        "position_group", 
        "player_name",
        "overall"
    )
    .orderBy(
        F.when(F.col("position_group") == "Goleiro", 1)
         .when(F.col("position_group") == "Defesa", 2)
         .when(F.col("position_group") == "Meio", 3)
         .when(F.col("position_group") == "Ataque", 4)
         .otherwise(5)
    )
)

print("TIME DOS SONHOS DO BRASIL (4-4-2)")
dream_team.display()

print(f"Total de jogadores no time: {dream_team.count()}")

# COMMAND ----------

# MAGIC %md
# MAGIC ### Desafio B√¥nus
# MAGIC
# MAGIC Voc√™ deve ter notado que **Neymar** aparece tanto entre os melhores jogadores de **ataque** quanto do **meio-campo**.  
# MAGIC Isso acontece porque o dataset cont√©m **m√∫ltiplas vers√µes do mesmo jogador**, inclusive atuando em **outras posi√ß√µes**, o que √© t√≠pico dos modos do *FIFA/Ultimate Team*.
# MAGIC
# MAGIC O seu desafio agora √© **refazer o exerc√≠cio anterior**, garantindo que **cada jogador apare√ßa apenas uma vez** no *DataFrame final*.
# MAGIC
# MAGIC - Caso o jogador possua mais de uma vers√£o (carta), **considere apenas aquela com o maior valor de `overall`**.  
# MAGIC - Em seguida, **reaplique a l√≥gica da forma√ß√£o 4-4-2**, selecionando os melhores por grupo de posi√ß√£o.
# MAGIC
# MAGIC ---
# MAGIC
# MAGIC ### üèÅ Entrega Esperada
# MAGIC Seu *DataFrame final* deve retornar **11 jogadores √∫nicos**, representando o **Dream Team do Brasil** na **forma√ß√£o t√°tica 4-4-2**, **sem repeti√ß√£o de atletas**, conforme os crit√©rios estabelecidos acima.
# MAGIC

# COMMAND ----------

from pyspark.sql import functions as F
from pyspark.sql.window import Window

posicao_goleiro = ["GK"]
posicoes_defesa = ["CB", "RB", "LB", "LWB", "RWB"]
posicoes_meio = ["CM", "CDM", "CAM", "LM", "RM"]  
posicoes_ataque = ["ST", "CF", "LW", "RW", "LF", "RF"]

window_jogador = Window.partitionBy("player_name").orderBy(F.desc("overall"))

jogadores_brasileiros_unicos = (
    fut_players
    .filter(F.col("nationality") == "Brazil")
    .withColumn("rank_versao", F.row_number().over(window_jogador))
    .filter(F.col("rank_versao") == 1) 
    .drop("rank_versao")
)

jogadores_classificados = jogadores_brasileiros_unicos.withColumn(
    "position_group",
    F.when(F.col("position").isin(posicao_goleiro), "Goleiro")
     .when(F.col("position").isin(posicoes_defesa), "Defesa")
     .when(F.col("position").isin(posicoes_meio), "Meio")
     .when(F.col("position").isin(posicoes_ataque), "Ataque")
     .otherwise("Outros")
)

window_posicao = Window.partitionBy("position_group").orderBy(F.desc("overall"))

dream_team_unicos = (
    jogadores_classificados
    .filter(F.col("position_group") != "Outros")
    .withColumn("rank_posicao", F.row_number().over(window_posicao))
    .filter(
        ((F.col("position_group") == "Goleiro") & (F.col("rank_posicao") <= 1)) |
        ((F.col("position_group") == "Defesa") & (F.col("rank_posicao") <= 4)) |
        ((F.col("position_group") == "Meio") & (F.col("rank_posicao") <= 4)) | 
        ((F.col("position_group") == "Ataque") & (F.col("rank_posicao") <= 2))
    )
    .select(
        "nationality",
        "position_group", 
        "player_name",
        "overall"
    )
    .orderBy(
        F.when(F.col("position_group") == "Goleiro", 1)
         .when(F.col("position_group") == "Defesa", 2)
         .when(F.col("position_group") == "Meio", 3)
         .when(F.col("position_group") == "Ataque", 4)
         .otherwise(5)
    )
)

print("TIME DOS SONHOS DO BRASIL - SEM REPETI√á√ïES (4-4-2)")
dream_team_unicos.display()

print(f"Total de jogadores √∫nicos no time: {dream_team_unicos.count()}")

# COMMAND ----------

# MAGIC %md
# MAGIC # Declara√ß√£o de Inexist√™ncia de Pl√°gio:
# MAGIC
# MAGIC 1. Eu sei que pl√°gio √© utilizar o trabalho de outra pessoa e apresentar como meu.
# MAGIC 2. Eu sei que pl√°gio √© errado e declaro que este notebook foi feito por mim.
# MAGIC 3. Tenho consci√™ncia de que a utiliza√ß√£o do trabalho de terceiros √© anti√©tico e est√° sujeito a medidas administrativas.
# MAGIC 4. Declaro tamb√©m que n√£o compartilhei e n√£o compartilharei meu trabalho com o intuito de que seja copiado e submetido por outra pessoa.

# COMMAND ----------

# MAGIC %md
# MAGIC # Fim da aula!
# MAGIC
# MAGIC Obrigado por participar do curso, voc√™ acaba de finalizar o M√≥dulo de Pyspark. Neste momento voc√™ j√° deve ser capaz de manipular seus dados no Spark, utilizando as bibliotecas que acabamos de aprender!
# MAGIC
# MAGIC Lembre-se que sempre que surgir alguma d√∫vida, voc√™ pode olhar a documenta√ß√£o do [PySpark](https://spark.apache.org/docs/latest/api/python/reference).